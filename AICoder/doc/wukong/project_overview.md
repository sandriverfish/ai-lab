# Wukong Project Overview

## Project Description
<!-- Provide a brief description of the Wukong project, its purpose, and goals -->
Wukong是一个SOP视觉引导及检查的产品，应用于工厂产线组装等领域，对产品组装过程SOP进行工序的视觉引导及检查，以减少人工组装错误（漏装、错装等）。

本项目完成了第一个版本（也就是1.0），我将逐步补齐相关的文档资料。目前主要的任务就是摸索出如何加入机器学习，能够结合V1.0的功能，可以用少量图片及标注训练，或者利用LLM等工具提升数据准备和训练的效率，希望step-by-step完成混合机器学习模型提升产品鲁棒性、准确率。这些步骤和进展可以记录在本文档中，有相应的检查项目以及给出建议需要我准备的内容。

生成的代码，可以通过github中转，运行设备可以同步代码在本地环境执行，例如Nvidia Jetson Xavier。

### 1. 项目目标及范围
Wukong主要完成的功能：
* SOP（Standard Operation Procedure）作业指导书的导入，通常是PDF格式；
* 拍照功能： 对安装在工厂产线的组装工位的组装产品（成品）进行拍照。
* 标记功能：对组装产品拍照的照片，标记需要进行组装视觉引导及检查的零件位置（在组装产品上）。一般存在多个零件，按照组装顺序进行标记。
* 视觉引导及检查功能：基于摄像头的图像，框出组装零件的位置，红色为未组装，绿色为完成（OK）,组装错误或超时为NG。
* 组装完成后，对组装结果进行评估，并生成报告。
* 对图像检查的补充说明：采用机器学习的方法，首先采集产品的照片进行预训练，能够识别产品以及产品不同立面（例如产品有前后、左右、上下等六个面），以及各个组装零件的位置。产品首先使用预训练模型完成视觉引导检查功能，后续随着产品的使用，可以对过程中积累的图像及标注数据进行新的训练。
* 工位环境：人战栗或坐在操作台前，组装产品长度50cm左右，深度40cm左右，高度在10cm~30cm不等；相机安装高度范围50cm~90cm，不影响组装工人的操作；工作台上方配有日光灯管。

### 名词定义
*

### 应用模式1
WK-1500接1路～6路工业相机（USB3.0），通过HDMI接显示器，提供Wukong视觉引导及检查功能。

### 应用模式2
WK1500提供后台服务（模型推理），可以连接多台前端WK-T20。WK-T20接1路工业相机（USB3.0），通过HDMI接显示器，与WK-1500配合（基于webrtc连接Jetson，并且Jetson提供AI服务，完成视觉引导及检查功能。

### 应用模式3
客户提出需求：导入产品3D文件，与实物进行对比视觉检查。目前先不处理，后续再研究。

### 产品体验期待
从产线组装人员的使用来看：
* 当组装产品到达组装工作台，Wukong系统可以快速识别组装产品，并且可以准确定位零件的组装位置。屏幕显示出要安装的组装位置（绿色框标识），正确安装后，屏幕显示下一个零件组装位置的标识框引导。
* 组装过程中，组装产品可以随意在镜头视野范围内调整位置和角度，悟空系统需要正确的识别组装产品和零件位置。
* 组装过程是增加零件的过程，所以产品识别从基座开始，需要准确的识别产品。
* 组装过程中，除了对零件组装进行有无的引导及检查，还能够进一步识别错误的组装零件，例如螺丝头不一致（十字/一字等）、接插件的线序错误（可以根据颜色和方向判断)，每个组装零件位置的识别速度要求在100ms完成。
* 组装过程是按照顺序完成的，每个工序正确完成屏幕显示OK，并且可以播放柔和的声音提示。如果出现漏装或超时，以及错误安装则需要告警。

以上适用于应用模式1和应用模式2.

### 基本指标
* 组装产品检测时间：小于300ms；
* 基准点查找时间：200ms~300ms；
* 检查点单次识别时间：小于300ms；
* 检查点数量：理论上不受限制；

## Architecture
<!-- Describe the overall architecture of Wukong -->
### V1.0 当前技术实现
V1.0 系统包括两个关键组件：
* WK-1500：基于Nvidia Jetson Xavier NX边缘服务器，安装了数据库服务器、Web服务器、后端管理应用（Java开发），以及管理前端（Vue.JS框架）。
* WK-T20：基于Rockchip RK3399(安卓10)，通过USB 3.0连接迈德相机，HDMI外接显示器。我们开发了安卓应用，通过OpenCV进行模板匹配产品，对于检查点做图像比较（主要是零件有无安装），基于Tensorflow Lite，以及使用MobileNet V3模型对图像进行特征值提取和比对。

### V1.5(过渡版本)
V1.5版本计划基于单一设备，使用Nvidia Jetson Xavier NX，直接连接USB工业相机，通过Ubuntu操作系统运行。使用Python + Qt开发用户界面，使用PaddlePaddle进行机器学习模型的训练和推理。

### V2.0(下一个版本)
技术升级考虑：
* 计划增加机器学习，并且结合现有的方式，尽量减少客户导入产品时的标注训练工作量。主要解决目前的对产品摆放位置有较为严格的要求，而且受光线等影响比对结果。
* 支持应用模式2，并且端侧支持跨平台（Linux, Windows, Android）

V2.0 关键技术验证主要包括：
* 适用于本项目的机器学习技术框架选择；(目前暂定使用PaddlePaddle，以及低代码工具PaddleX)
* 选定技术框架后，准备数据、模型调优(FINE TUNING)或训练; 由于缺乏数据集，可以选择公开的数据集跑完流程。注意：基于Jetson Xavier NX进行训练。
* 进行测试验证，主要考察一张图片的用时（产线上的操作对时间敏感）等，形成优化方案，评估是否可以用于实际。
* 假如验证成功，对于导入新项目，需要做什么准备工作？（如何准备产品照片、标注等）

### V2.5
* 支持三层架构，第一层前端设备，连接工业相机、显示设备以及其他外设（例如机械臂）；
* 第二层，边缘AI设备，与前端设备协作共同完成工位的SOP视觉引导和检查；
* 第三层，控制中心，完成整体系统设备的管理和监控。

## Key Components
<!-- List and describe the main components of the system -->
### 2. 项目架构组件
Wukong项目硬件组成
* WK-1500: 基于Nvidia Jetson Xavier NX的边缘处理器，内置了四口千兆交换机，可以连接WK-T20终端；
   * 操作系统为Ubuntu 20.04，JetPack版本为5.1.4；
   * 安装PaddlePaddle-GPU 3.0.0版本，PaddleX 3.0.0-rc版本；
   * Wukong应用软件（本项目需要开发）
* WK-T20: 基于Rockchip RK3576或RK3399的前端设备；
   * 安卓10操作系统；
   * Wukong端侧应用软件；
* 工业相机：选择迈德威视或海康的USB3.0工业相机；

## Technologies Used
<!-- List the technologies, frameworks, and libraries used in the project -->

### 硬件技术

* Nvidia Jetson Xavier NX (WK-1500)
* Rockchip RK3576/RK3399 (WK-T20)
* 工业相机：迈德威视/海康 USB3.0工业相机

### 软件技术

#### 服务端 (WK-1500)

* 操作系统: Ubuntu 20.04, JetPack 5.1.4
* 深度学习框架: PaddlePaddle-GPU 3.0.0-rc, PaddleX 3.0.0-rc
* 后端: Java Spring Boot
* 前端: Vue.js
* 数据库服务: MariaDB
* Web服务器: Nginx

#### 客户端 (WK-T20)

* 操作系统: Android 10
* 图像处理: OpenCV
* 深度学习: TensorFlow Lite, MobileNet V3
* WebRTC (用于与Jetson通信)

## API Documentation
<!-- Provide information about the API endpoints, request/response formats -->

### 主机与终端通信API

#### V1.0 当前API

根据系统手册中的信息，V1.0版本主机与终端之间存在以下API通信：

1. **终端激活API**
   - 终端通过Terminal Code向主机请求激活
   - 主机验证Terminal Code并返回激活状态
   - 端点: `/api/v1/device/activate`
   - 方法: POST
   - 请求格式: `{ "terminalCode": "string" }`
   - 响应格式: `{ "status": "success|failed", "deviceId": "string" }`

2. **作业同步API**
   - 主机向终端推送作业流程
   - 终端主动从主机获取作业流程
   - 端点: `/api/v1/job/sync`
   - 方法: GET/POST
   - 请求格式: `{ "deviceId": "string" }`
   - 响应格式: `{ "status": "success|failed", "jobProcesses": [...] }`

3. **远程截图API**
   - 主机请求终端上传实时截图
   - 终端响应并上传当前画面
   - 端点: `/api/v1/device/screenshot`
   - 方法: POST
   - 请求格式: `{ "deviceId": "string" }`
   - 响应格式: 图像数据(Base64编码)

4. **设备管理API**
   - 设备绑定/解绑
   - 设备状态监控
   - 设备日志收集
   - 端点: `/api/v1/device/{action}`
   - 方法: GET/POST
   - 请求/响应格式: 根据具体操作而定

5. **作业执行API**
   - 作业流程执行状态上报
   - 作业结果记录
   - 端点: `/api/v1/job/execute`
   - 方法: POST
   - 请求格式: `{ "deviceId": "string", "jobId": "string", "status": "string", ... }`
   - 响应格式: `{ "status": "success|failed" }`

#### V2.0 计划API变更

V2.0版本将在保持V1.0 API向后兼容的基础上，增加以下API：

1. **AI模型服务API**
   - 提供图像识别和检测服务
   - 端点: `/api/v2/ai/detect`
   - 方法: POST
   - 请求格式: 图像数据 + 检测参数
   - 响应格式: 检测结果JSON

2. **WebRTC信令API**
   - 建立WebRTC连接的信令服务
   - 端点: `/api/v2/webrtc/signal`
   - 方法: POST
   - 请求/响应格式: WebRTC标准信令格式

3. **数据同步API**
   - 提供增量数据同步功能
   - 端点: `/api/v2/sync`
   - 方法: GET/POST
   - 请求格式: `{ "deviceId": "string", "lastSyncTime": "timestamp" }`
   - 响应格式: 增量数据JSON

4. **模型训练API**
   - 提供模型训练和更新功能
   - 端点: `/api/v2/ai/train`
   - 方法: POST
   - 请求格式: 训练参数JSON
   - 响应格式: 训练状态和结果

### 通信协议演进

#### V1.0 HTTP REST API

V1.0版本主要使用HTTP REST API进行通信，特点是：
- 简单可靠，易于实现
- 无状态，每次请求都包含完整信息
- 适合间歇性通信
- 不适合实时数据传输

#### V2.0 WebRTC实时通信

V2.0版本将引入WebRTC通信，特点是：
- 支持实时音视频和数据传输
- 点对点通信，减少服务器负担
- 适合大量图像数据传输
- 支持在网络条件不佳时的自适应调整

在应用模式2中，WK-T20通过WebRTC与WK-1500通信，实现AI服务调用。WebRTC通信流程：
1. 通过信令服务器建立连接
2. 交换SDP和ICE候选项
3. 建立点对点连接
4. 传输图像数据和检测结果

## Data Models
<!-- Describe the data models and database schema -->

### 核心数据模型

根据系统手册，Wukong系统包含以下核心数据模型：

#### V1.0 当前数据模型

1. **作业流程 (Job Process)**
   * 包含多个作业指引
   * 属性：名称、描述、创建时间、更新时间、状态等

2. **作业指引 (Job Instruction)**
   * 包含多个作业项
   * 属性：名称、描述、顺序号、超时时间等

3. **作业项 (Job Item)**
   * 包含一张主图像、一个基准搜索区、一个基准点、若干检测点
   * 属性：名称、描述、图像路径、状态等

4. **基准搜索区 (Base Search Area)**
   * 属性：坐标、尺寸、搜索参数等

5. **基准点 (Base Point)**
   * 属性：坐标、匹配参数等

6. **检测点 (Check Point)**
   * 属性：坐标、尺寸、检测参数、超时时间等

7. **设备 (Device)**
   * 属性：终端编码、名称、IP地址、状态、绑定时间等

8. **作业记录 (Job Process Log)**
   * 记录作业执行的历史数据
   * 属性：作业流程ID、开始时间、结束时间、结果状态等

#### V2.0 计划数据模型扩展

V2.0版本将在保持V1.0数据模型向后兼容的基础上，扩展以下数据模型：

1. **AI模型 (AI Model)**
   * 属性：模型名称、版本、类型、参数、创建时间、更新时间等
   * 关联：可关联到多个作业流程

2. **训练数据集 (Training Dataset)**
   * 属性：数据集名称、描述、图像数量、标注状态等
   * 关联：关联到AI模型

3. **检测结果 (Detection Result)**
   * 属性：检测时间、检测点ID、检测结果、置信度等
   * 关联：关联到作业记录

4. **产品模板 (Product Template)**
   * 属性：产品名称、描述、特征向量等
   * 关联：关联到作业流程

5. **终端配置 (Terminal Configuration)**
   * 属性：终端ID、平台类型、硬件规格、软件版本等
   * 关联：关联到设备

### 数据库架构

#### V1.0 数据库架构

V1.0版本使用MariaDB关系型数据库，主要表结构如下：

* **job_process**: 存储作业流程信息
* **job_instruction**: 存储作业指引信息，外键关联job_process
* **job_item**: 存储作业项信息，外键关联job_instruction
* **base_search_area**: 存储基准搜索区信息，外键关联job_item
* **base_point**: 存储基准点信息，外键关联job_item
* **check_point**: 存储检测点信息，外键关联job_item
* **device**: 存储设备信息
* **job_process_log**: 存储作业记录信息，外键关联job_process和device

#### V2.0 数据库架构扩展

V2.0版本将在V1.0数据库架构基础上，增加以下表结构：

* **ai_model**: 存储AI模型信息
* **training_dataset**: 存储训练数据集信息，外键关联ai_model
* **detection_result**: 存储详细检测结果，外键关联job_process_log和check_point
* **product_template**: 存储产品模板信息，外键关联job_process
* **terminal_configuration**: 存储终端配置信息，外键关联device

## Configuration
<!-- Document configuration options and environment variables -->

### 系统配置选项

根据系统手册，Wukong系统提供以下配置选项：

1. **网络配置**
   * 主机内部网络：默认IP为10.10.8.1，提供DHCP服务
   * 外部网络连接：可连接外部路由器以获取NTP时间同步

2. **设备配置**
   * 终端编码：每个终端需要唯一的Terminal Code进行激活
   * 终端服务器地址：默认为[http://10.10.8.1](http://10.10.8.1)

3. **摄像头配置**
   * 支持USB3.0工业相机
   * 视野要求：物距500~800mm，视野500x400mm
   * 当前相机规格：800万像素，3840*2160像素，像元2um，靶面尺寸1/1.8"

4. **作业流程配置**
   * 超时设置：可为每个作业项设置超时时间
   * 检测参数：可配置基准搜索区、基准点和检测点的参数

5. **系统管理配置**
   * 用户管理：可配置不同权限的用户
   * 设备调度：可设置终端的开关机定时任务
   * 系统升级：支持作业主机和终端的软件升级

## Deployment
<!-- Explain deployment procedures and requirements -->

### 部署流程

#### V1.0 当前部署流程

根据系统手册，Wukong V1.0系统的部署流程如下：

1. **硬件安装**
   * 作业主机连接电源和网络
   * 作业终端连接显示器、相机、鼠标、键盘和网络
   * 相机安装在不影响工位人工作业的位置，确保视野合适

2. **系统激活**
   * 作业主机启动后，通过浏览器访问[http://10.10.8.1](http://10.10.8.1)
   * 在Device Management菜单中获取Terminal Code
   * 作业终端开机后，输入Terminal Code进行激活

3. **作业配置**
   * 获取作业终端截图
   * 创建作业流程(Job Process)
   * 添加作业指引(Job Instruction)
   * 添加作业项(Job Item)
   * 设置基准搜索区、基准点和检测点
   * 发布作业流程

4. **作业同步**
   * 从作业主机远程同步作业流程到终端
   * 或在作业终端上主动获取作业流程

5. **系统验证**
   * 在作业终端上运行作业流程
   * 验证基准点识别和检测点检测功能
   * 检查作业记录和报告

#### V2.0 计划部署流程

Wukong V2.0系统将在V1.0部署流程基础上，增加以下步骤：

1. **平台选择**
   * 根据工厂环境选择合适的终端平台（Android/Linux/Windows）
   * 安装对应平台的客户端软件

2. **AI模型配置**
   * 选择预训练模型或导入自定义模型
   * 配置模型参数和推理设置

3. **WebRTC连接配置**
   * 配置信令服务器地址
   * 设置媒体传输参数
   * 测试点对点连接

4. **分布式部署**
   * 配置主服务器和从服务器角色
   * 设置负载均衡参数
   * 配置故障转移机制

5. **数据迁移**
   * 从V1.0系统迁移数据到V2.0系统
   * 验证数据完整性和一致性

### 部署要求

#### V1.0 当前部署要求

* **硬件要求**：
  * WK-1500作业主机：Nvidia Jetson Xavier NX
  * WK-T20作业终端：Rockchip RK3576或RK3399
  * 工业相机：迈德威视或海康的USB3.0工业相机
  * 显示器、鼠标、键盘等外设

* **网络要求**：
  * 主机和终端之间需要通过网线连接
  * 建议主机连接外部路由器以获取NTP时间同步

* **环境要求**：
  * 相机安装位置需确保不影响工位人工作业
  * 光线条件需稳定，避免强光直射或光线不足

#### V2.0 计划部署要求

* **硬件要求**：
  * WK-1500作业主机：Nvidia Jetson Xavier NX（与V1.0相同）
  * 终端设备：
    * Android：Rockchip RK3576/RK3399
    * Linux：x86_64架构PC或工控机
    * Windows：x86_64架构PC或工控机
  * 工业相机：支持更多型号的USB3.0工业相机
  * 显示器、鼠标、键盘等外设

* **网络要求**：
  * 支持有线和无线网络连接
  * 建议千兆以太网以保证WebRTC通信质量
  * 支持NAT穿透和TURN服务器配置

* **软件要求**：
  * 服务端：Ubuntu 20.04 LTS，JetPack 5.1.4或更高版本
  * 客户端：
    * Android 10或更高版本
    * Ubuntu 20.04/22.04 LTS
    * Windows 10/11

* **存储要求**：
  * 服务端：至少128GB存储空间，用于存储模型和数据
  * 客户端：至少32GB存储空间

### 部署模式对比

| 特性 | V1.0 部署 | V2.0 部署 |
|------|-----------|-----------|
| 支持的终端平台 | 仅Android | Android, Linux, Windows |
| 部署架构 | 单机或简单主从 | 分布式，支持多级部署 |
| 通信方式 | HTTP API | HTTP API + WebRTC |
| 离线工作能力 | 有限 | 增强 |
| 自动更新 | 不支持 | 支持 |
| 远程管理 | 基本支持 | 全面支持 |
| 数据备份 | 手动 | 自动 + 手动 |
| 故障恢复 | 基本 | 高级（自动故障转移） |

## Integration Points
<!-- Describe how Wukong integrates with other systems -->

### 系统集成点

Wukong系统提供以下集成点：

1. **硬件集成**
   * 支持多种工业相机集成（迈德威视、海康等）
   * 可与工厂现有显示设备集成

2. **网络集成**
   * 可连接工厂网络以获取NTP时间同步
   * 支持通过网络远程管理和监控

3. **数据集成**
   * 作业记录可导出为报表
   * 可通过API获取系统状态和作业数据

4. **SOP集成**
   * 支持导入现有的SOP（Standard Operation Procedure）作业指导书
   * 可与工厂现有的SOP管理系统集成

5. **AI模型集成**
   * 支持导入预训练的AI模型
   * 可与其他AI训练平台集成，用于模型优化

## Known Limitations
<!-- Document any known limitations or issues -->

### 系统限制

根据项目描述和系统手册，Wukong系统存在以下限制：

#### V1.0 当前版本限制

1. **产品识别限制**
   * 对产品摆放位置有较为严格的要求，需要保持相对固定的位置和角度
   * 受光线等环境因素影响较大，光线变化可能导致识别失败
   * 基于模板匹配的方法对产品外观变化适应性较差

2. **检测能力限制**
   * 主要基于模板匹配和图像比较，对复杂场景适应性有限
   * 对于细微差异的检测准确性有待提高
   * 难以区分相似外观但不同功能的零件

3. **性能限制**
   * 每个组装零件位置的识别速度要求在100ms完成，当前可能存在性能瓶颈
   * 多路相机同时工作时可能存在资源竞争
   * 模板匹配算法在复杂场景下计算量大，影响响应速度

4. **训练数据限制**
   * 缺乏足够的训练数据集
   * 新产品导入时需要大量标注工作
   * 现有模型难以迁移到新产品上

5. **网络限制**
   * 主机和终端之间需要稳定的网络连接
   * WebRTC通信在网络不稳定时可能出现延迟

#### V2.0 预期改进但仍存在的限制

1. **产品识别限制**
   * 虽然对位置和光线的适应性会提高，但极端情况下仍可能出现识别问题
   * 对于全新产品类型仍需要一定量的训练数据

2. **检测能力限制**
   * 对于极其相似的零件仍可能存在误判
   * 在复杂背景下可能存在干扰

3. **性能限制**
   * 深度学习模型虽然准确性提高，但可能增加计算负担
   * 多终端并发时可能存在资源竞争

4. **训练数据限制**
   * 虽然减少了标注工作量，但新产品仍需要一定量的样本数据
   * 迁移学习效果受产品相似度影响

5. **跨平台兼容性**
   * 不同平台的性能和功能可能存在差异
   * 需要维护多个平台的代码

## 当前计划任务

我们将按照V1.5版本（内部验证版本）推进项目，以V1.0作为参考，开发基于单一Jetson Xavier NX设备的解决方案。以下是当前的计划任务：

### 1. V1.5版本开发计划

* **目标**：开发内部验证版本，验证技术可行性，为V2.0生产版本奠定基础
* **时间线**：2024年Q2完成
* **参考**：V1.0已实现版本（参考资料已提供）
* **验收标准**：
  * 单一设备（Jetson Xavier NX）直接连接USB相机
  * 在Ubuntu上运行的用户界面
  * 深度学习模型与模板匹配的混合识别
  * 满足100ms响应时间要求
  * 对光线和位置变化具有更好的适应性

### 2. 机器学习集成计划

我们已创建详细的机器学习集成计划，包括以下关键内容：

* **技术选择**：使用PaddlePaddle 3.0.0-rc和PaddleX 3.0.0-rc作为主要ML框架
* **混合识别方法**：结合现有模板匹配和新的深度学习模型
* **实施阶段**：
  * 阶段1：环境搭建和基准测试（1-2周）
  * 阶段2：概念验证（3-4周）
  * 阶段3：核心实现（5-8周）
  * 阶段4：测试和优化（9-10周）

详细内容请参见：[机器学习集成计划](ml_integration_plan_cn.md)

### 3. Jetson开发环境配置

为支持V1.5版本开发，我们编写了Jetson Xavier NX的详细配置指南：

* **系统设置**：JetPack 5.1.4安装和配置
* **PaddlePaddle安装**：GPU版本配置和优化
* **性能基准测试**：验证硬件性能满足要求
* **相机驱动配置**：直接连接USB工业相机

详细内容请参见：[Jetson设置指南](jetson_setup_guide.md)

### 4. 用户界面开发

为V1.5版本开发基于Ubuntu的用户界面：

* **框架选择**：Python + Qt
* **功能需求**：参考V1.0的Android界面，并进行优化
* **设计原则**：简洁、直观、响应快速
* **跨平台考虑**：为未来支持Windows和Android做准备

### 5. 数据准备策略

为训练有效的机器学习模型，我们制定了数据收集和准备策略：

* **数据要求**：每种产品至少50-100张图像，每种组件20-30张图像
* **数据增强**：通过旋转、缩放、光照变化等方法扩充数据集
* **数据管理**：版本控制和质量评估流程

详细内容请参见：[数据准备指南](data_preparation_guide.md)

### 6. 近期工作计划

接下来2-4周我们将专注于以下任务：

* **开发环境搭建**：配置Jetson Xavier NX开发环境，安装必要软件
* **UI原型开发**：使用Python + Qt开发基本界面原型
* **相机驱动测试**：测试USB相机直接连接的稳定性和性能
* **基准测试**：测量当前模板匹配性能作为基准
* **初始数据收集**：收集和标注初始训练数据集
* **概念验证开发**：实现简单的ML模型并测试性能

## Version Roadmap

### 版本演进计划

Wukong系统的版本演进计划如下：

#### V1.0 (当前版本)

* **发布时间**：2024年Q4
* **核心功能**：
  * 基于模板匹配的产品识别
  * 基于图像比较的零件检测
  * 单机版应用模式
  * 基本的SOP导入和管理
* **技术栈**：
  * 服务端：Java + Vue.js + MariaDB
  * 客户端：Android + OpenCV + TensorFlow Lite

* **详细功能列表**（从《悟空SOP作业检查系统手册》提取）：

  **1. 系统组成**
  * 作业主机（1台）：基于Jetson Xavier NX
  * 作业终端（1-3台）：基于Android设备
  * 摄像头（1-3台）：USB3.0工业相机

  **2. 作业配置功能**
  * 远程截图：从作业主机获取终端实时截图
  * 作业流程（Job Process）创建和管理
  * 作业指引（Job Instruction）创建和管理
  * 作业项（Job Item）创建和管理
  * 基准搜索区（Base Search Area）设置
  * 基准点（Base Point）设置
  * 检测点（Check Point）设置
  * 作业流程发布和同步

  **3. 作业执行功能**
  * 作业同步：主机远程同步和终端主动获取两种方式
  * 作业运行：基准点搜索和检测点检测
  * 循环作业支持：完成一次作业后自动执行下一次
  * 超时检测：检测项超时后发生NG并中断流程

  **4. 终端管理功能**
  * 终端绑定和解绑
  * 远程截图
  * 定时任务管理（开关机）
  * 软件版本管理
  * 升级策略管理
  * 运行日志收集

  **5. 作业管理功能**
  * 作业流程管理
  * 作业记录查询和统计

  **6. 系统管理功能**
  * 系统参数配置
  * 系统升级
  * 用户管理
  * 网络配置管理

#### V1.5 (内部验证版本)

* **计划时间**：2024年Q2
* **版本定位**：
  * 作为内部技术验证版本，为V2.0生产版本奠定基础
  * 简化系统架构，专注于核心功能验证
  * 以V1.0为参考，重新设计单设备解决方案
* **核心改进**：
  * 简化架构：仅使用Jetson Xavier NX直接连接USB相机
  * 初步引入深度学习模型（PaddlePaddle）
  * 优化模板匹配算法
  * 在Ubuntu上开发新的用户界面
  * 增强数据管理功能
* **技术栈**：
  * 硬件：Nvidia Jetson Xavier NX + USB工业相机
  * 操作系统：Ubuntu 20.04 (JetPack 5.1.4)
  * 深度学习：PaddlePaddle 3.0.0-rc + PaddleX
  * 图像处理：OpenCV
  * 用户界面：Python + Qt（跨平台框架）
* **技术验证目标**：
  * 验证深度学习模型性能和准确性
  * 测试直接相机驱动的稳定性和性能
  * 评估跨平台UI框架的用户体验
  * 测量系统响应时间是否满足100ms要求
  * 验证在不同光线和位置条件下的识别稳定性

* **建议项目文件夹结构 (V1.5)**:

  ```
  wukong_v15/
  ├── main.py                 # 主应用程序入口脚本
  ├── requirements.txt        # Python 依赖包列表
  ├── config/                 # 配置文件目录
  │   ├── settings.yaml       # 通用应用设置、模型路径、相机参数等
  │   └── logging.conf        # 日志配置
  │
  ├── wukong_app/             # 核心应用源代码包
  │   ├── __init__.py
  │   ├── ui/                 # Qt 用户界面相关代码
  │   │   ├── __init__.py
  │   │   ├── main_window.py  # 主窗口逻辑
  │   │   ├── views/          # UI 视图/屏幕 (可选)
  │   │   │   └── __init__.py
  │   │   ├── widgets/        # 自定义可复用 UI 部件
  │   │   │   └── __init__.py
  │   │   └── assets/         # 静态 UI 资源 (图标, 样式表 .qss)
  │   │       └── icons/
  │   │
  │   ├── core/               # 核心业务逻辑、SOP 管理、状态控制
  │   │   ├── __init__.py
  │   │   ├── sop_processor.py # 处理 SOP 步骤和逻辑
  │   │   ├── state_manager.py # 管理应用状态
  │   │   └── job_manager.py   # 管理作业配置 (加载, 保存)
  │   │
  │   ├── vision/             # 计算机视觉和 ML 推理相关代码
  │   │   ├── __init__.py
  │   │   ├── camera.py       # 相机接口 (连接, 捕获帧)
  │   │   ├── preprocess.py   # 图像预处理函数
  │   │   ├── recognition.py  # 主要识别逻辑 (结合模板匹配 & ML)
  │   │   └── inference/      # ML 模型加载和推理执行
  │   │       ├── __init__.py
  │   │       └── paddle_adapter.py # PaddlePaddle 模型推理封装
  │   │
  │   └── utils/              # 通用工具函数和类
  │       ├── __init__.py
  │       └── helpers.py      # 通用辅助函数
  │
  ├── models/                 # 存储训练好的 ML 模型文件
  │   └── product_detector/   # 示例: 产品检测模型
  │       ├── model.pdparams
  │       └── model.pdmodel
  │   └── part_classifier/    # 示例: 零件分类模型
  │       ├── model.pdparams
  │       └── model.pdmodel
  │
  ├── data/                   # 存储运行时数据、日志、临时文件
  │   ├── logs/               # 应用日志
  │   └── captured/           # 示例: 保存捕获图像用于调试
  │
  ├── scripts/                # 独立工具脚本 (例如测试, 数据转换)
  │   └── test_camera_feed.py # 快速测试相机连接的脚本
  │
  └── tests/                  # 自动化测试 (单元, 集成)
      ├── __init__.py
      ├── test_core_logic.py
      └── test_vision_components.py
  ```

* **功能列表**（相比V1.0的变化）：

  **1. 系统组成变化**
  * 简化为单一设备：Jetson Xavier NX直接连接USB工业相机
  * 取消Android终端，改为在Jetson上运行UI
  * 支持1-3路USB工业相机直接连接

  **2. 作业配置功能**
  * 保留V1.0的核心作业配置功能
  * 增强基准点搜索算法，结合深度学习提高识别准确性
  * 增加对不同光线条件下的模板适应性
  * 简化作业流程创建界面，提高用户体验

  **3. 作业执行功能**
  * 混合识别方法：结合模板匹配和深度学习模型
  * 提高对产品位置变化的适应性
  * 优化检测速度，满足100ms响应时间要求
  * 增强对相似零件的区分能力

  **4. 系统管理功能**
  * 简化系统配置，专注于单设备场景
  * 增加模型管理功能，支持模型导入和更新
  * 增加系统性能监控功能
  * 提供数据备份和恢复功能

  **5. 新增功能**
  * 深度学习模型训练界面
  * 数据集管理工具
  * 模型性能评估工具
  * 系统资源监控面板

##### V1.5 改进建议

为确保 V1.5 验证阶段的有效性并更好地支撑 V2.0 目标，建议在 V1.5 计划中进一步明确以下方面：

1.  **明确混合识别策略**：详细定义深度学习与模板匹配的协同工作方式（例如，主次关系、触发条件、结果融合逻辑）。
2.  **具体化 ML 验证目标**：清晰界定 V1.5 需验证的 ML 功能点（如提升特定场景下的鲁棒性、初步错误检测能力），明确模型类型及基础性能指标。
3.  **强化数据策略**：设定更具体的验证数据量目标，规划数据增强及合成数据策略，建立初步的数据质量评估流程。
4.  **细化性能基准测试**：明确 100ms 响应时间的测试标准（端到端/推理、测试配置、场景、数据集）。
5.  **增加风险缓解计划**：简述 ML 验证未达预期时的应对预案（如技术回退、调整目标、增加投入）。
6.  **界定最小可行 UI 范围**：明确 V1.5 验证阶段必需的核心 UI 功能，避免过度开发。
7.  **明确 V1.0 业务逻辑集成范围**：说明 V1.5 需要实现 V1.0 业务逻辑的程度，明确验证重点是底层视觉技术还是包含上层应用逻辑。
8.  **关注 Jetson 资源管理**：计划中加入对 Jetson 资源（CPU/GPU/内存）的监控与管理考量，评估 UI 与 ML 并发运行的影响。
9.  **考虑架构演进**：在 V1.5 代码设计中考虑模块化与接口，为 V2.0 的分布式、跨平台架构演进奠定基础。

#### V2.0 (目标版本)

* **计划时间**：2024年Q4
* **核心功能**：
  * 基于深度学习的产品识别
  * 高精度零件检测
  * 多终端分布式应用模式
  * 跨平台客户端支持（Ubuntu、Windows、Android）
  * 自适应环境变化
  * 3D文件导入与比对（应用模式3）
* **技术栈**：
  * 核心引擎：Python + PaddlePaddle + OpenCV
  * 用户界面：跨平台UI框架（Python + Qt）
  * 数据库：SQLite/PostgreSQL
  * 通信：WebRTC（用于分布式模式）
  * 3D处理：Open3D/PyTorch3D

* **功能列表**（相比V1.5的增强）：

  **1. 系统架构**
  * 多终端分布式架构：支持中心服务器+多客户端模式
  * 跨平台支持：Ubuntu、Windows、Android
  * 云边协同：支持边缘设备和云服务协同工作

  **2. 识别能力**
  * 主要基于深度学习的产品识别，模板匹配作为备选
  * 自适应环境变化：光线、位置、角度等
  * 零件细节识别：螺丝头类型、接插件线序等
  * 支持少量样本学习和迁移学习

  **3. 3D功能**
  * 3D文件导入与实物比对
  * 3D模型可视化
  * 3D测量和分析

  **4. 分布式功能**
  * 基于WebRTC的实时通信
  * 分布式AI推理
  * 负载均衡和故障转移
  * 集中式管理和监控

  **5. 数据管理**
  * 高级数据分析和报表
  * 历史数据挖掘和趋势分析
  * 自动数据备份和恢复
  * 数据安全和访问控制

  **6. 系统集成**
  * 开放API接口
  * 与MES/ERP系统集成
  * 与其他工业系统集成
  * 支持标准工业协议

### 技术迁移路径

从V1.0到V2.0的技术迁移路径包括：

1. **架构迁移**
   * V1.0：Jetson Xavier NX服务端 + Android客户端
   * V1.5：单一Jetson Xavier NX直接连接相机
   * V2.0：多平台支持（Jetson、PC、移动设备）

2. **识别算法迁移**
   * V1.0：主要使用OpenCV模板匹配
   * V1.5：混合使用模板匹配和PaddlePaddle深度学习模型
   * V2.0：主要使用深度学习模型，模板匹配作为备选

3. **用户界面迁移**
   * V1.0：Android原生UI
   * V1.5：Ubuntu上的跨平台UI框架
   * V2.0：完整支持Android、Linux和Windows平台

4. **数据模型兼容性**
   * V1.5：简化数据模型，专注于单设备场景
   * V2.0：扩展数据模型支持多设备协作
   * 提供数据迁移工具

5. **跨平台UI建议**

为了实现V1.5到V2.0的平台迁移，我们建议以下跨平台UI框架选项：

* **Qt框架**：
  * 优势：成熟稳定，原生性能，良好的C++集成，适合工业应用
  * 劣势：学习曲线较陡，许可证成本考虑

* **Flutter**：
  * 优势：单一代码库支持多平台，现代UI设计，热重载开发
  * 劣势：与原生系统集成需要额外工作，性能密集型任务可能需要原生代码

* **Electron**：
  * 优势：基于Web技术，开发速度快，可利用现有Web开发技能
  * 劣势：资源消耗较大，不适合资源受限设备

* **Python + Qt/GTK**：
  * 优势：开发速度快，与机器学习工具链集成良好
  * 劣势：打包和分发较复杂，性能可能不如原生应用

**推荐方案**：考虑到Jetson设备的特性和机器学习集成需求，我们建议使用**Python + Qt**作为V1.5的UI框架。这将提供：

* 与PaddlePaddle无缝集成
* 良好的性能和原生外观
* 相对简单的开发流程
* 未来可迁移到其他平台

## Future Development
<!-- Outline plans for future development -->

### 未来发展计划

根据项目描述和版本路线图，Wukong系统的未来发展计划包括：

1. **技术升级**
   * 增加机器学习能力，结合现有方式
   * 减少客户导入产品时的标注训练工作量
   * 提高对产品摆放位置的适应性
   * 减少光线等环境因素的影响

2. **关键技术验证**
   * 选择适用于本项目的机器学习技术框架
   * 准备数据、模型调优或训练
   * 测试验证，优化性能
   * 简化新项目导入流程

3. **功能增强**
   * 提高零件识别的准确性和速度
   * 增强对错误组装零件的识别能力（如螺丝头不一致、接插件线序错误等）
   * 改进用户界面和交互体验

4. **系统扩展**
   * 支持更多类型的工业相机
   * 增加更多的应用模式
   * 提供更丰富的数据分析和报表功能

5. **长期规划 (V3.0及以后)**
   * 引入边缘计算和云端协同
   * 支持更复杂的组装场景
   * 集成工业物联网功能
   * 提供完整的数字孪生解决方案

## 常见问题（FAQ）

### 1. 系统同步时钟(NTP)如何设定？

系统设备保持同步的时钟非常有必要，建议在部署项目中指定可以连接的内部或公网 NTP 时钟服务器。该时钟服务器将会配置到系统的各个设备，以保持时钟同步。

### 2. 工位设计了多套作业指导流程，如何设置生效？

每个工位可以设置多套作业指导，系统管理员可以根据生产任务进行灵活调整。设置当前有效的作业指导流程。另外，如果只需要单机操作，也可以在工位的前端设备进行手工设置。

### 3. 操作时系统没有提示，该怎么办？

操作时，如有可能可以再尝试一次，系统操作的每一个工序都有设置超时，如果报错，请联系现场的技术支持人员。

技术支持人员需要检查后台的作业日志，找到记录并分析对比情况，例如环境光线变化、组装零件发生变化等。

### 4. 工站屏幕黑屏如何处理？

检查屏幕电源是否正常，然后检查前端设备的电源指示灯是否正常，检查 HDMI 连接线。

### 5. 相机画面黑屏，如何处理?

检查相机的供电，或者相机与前端设备的 USB 连接线是否正常。

### 6. 相机如何设置

#### 注意事项

1. 每个工位制定作业指导前，先进入应用的【相机设置】调试好相机，尤其是符合操作员习惯的水平方向与垂直方向。**在相机的水平、垂直镜像选项为【否】的情况下调整相机到习惯视角**。
2. 基准点搜索区域，可以定义特征比较显著的区域，区域尺寸也不宜过大（可能会影响速度）。每次进行作业检查会验证基准点，后续做成异步处理。
3. 主图像的远程截屏，目前没有预览功能，下一个版本增加。
4. 参照系的对应顺序：

   1. 操作员习惯的布局。
   2. 相机设置中的预览图像，与实际布局对应，按照水平、垂直方向检查，先调整相机方向。
   3. 需要的话调整相机中水平、垂直镜像参数。
   4. 拍照上传后的照片作为主图像，作业检查项，按照操作顺序基于主图像进行显示。识别框如有不同，可以做水平、垂直方向的调整。
